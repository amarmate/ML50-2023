{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Data imports\n",
    "data = pd.read_csv('Data/cleaned_data.csv', index_col=0)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Model imports\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Metrics imports\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X_train, y_train, X_test, y_test, just_score=False): \n",
    "    fit = model.fit(X_train, y_train)\n",
    "    y_pred = fit.predict(X_test)\n",
    "    if just_score:\n",
    "        return fit, f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "    print('Precision: ', precision_score(y_test, y_pred))\n",
    "    print('Recall: ', recall_score(y_test, y_pred))\n",
    "    print('F1: ', f1_score(y_test, y_pred))\n",
    "    print('Confusion matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "    print('Classification report: \\n', classification_report(y_test, y_pred))\n",
    "    return fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['invisits', 'non_lab_procedures', 'num_diag', 'num_meds', 'num_tests', 'length_stay', 'sum_visits']\n",
    "categorical_features = ['admission_source','diag_3','admission_type','glucose_test_result','diag_2','diag_1','race','disposition','a1c_test_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = data[data['readmitted_binary'].notna()]\n",
    "y = X['readmitted_binary']\n",
    "X = X.drop(['readmitted_binary', 'readmitted_multiclass', 'diag_1_description', 'diag_2_description', 'diag_3_description', 'patient_id'], axis=1)\n",
    "\n",
    "# For the final test set\n",
    "X_final_test = data[data['readmitted_binary'].isna()]\n",
    "X_final_test = X_final_test.drop(['readmitted_binary', 'readmitted_multiclass', 'diag_1_description', 'diag_2_description', 'diag_3_description', 'patient_id'], axis=1)\n",
    "\n",
    "# Age should be considered a categorical variable (ordinal)\n",
    "categorical_features = list(set(categorical_features) - set(['age']))\n",
    "\n",
    "# Change the categorical features to strings\n",
    "for feature in categorical_features:\n",
    "    X[feature] = X[feature].astype(str)\n",
    "    X_final_test[feature] = X_final_test[feature].astype(str)\n",
    "\n",
    "# Initialize the one hot encoder\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the encoder on the categorical features\n",
    "encoded = encoder.fit_transform(X[categorical_features])\n",
    "encoded_final_test = encoder.transform(X_final_test[categorical_features])\n",
    "\n",
    "# Convert the encoded features into a DataFrame with appropriate column names\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical_features), index=X.index)\n",
    "encoded_df_final_test = pd.DataFrame(encoded_final_test, columns=encoder.get_feature_names_out(categorical_features), index=X_final_test.index)\n",
    "\n",
    "# Concatenate the original DataFrame X with the encoded DataFrame\n",
    "X = pd.concat([X, encoded_df], axis=1)\n",
    "X_final_test = pd.concat([X_final_test, encoded_df_final_test], axis=1)\n",
    "\n",
    "# Drop the original categorical features as they have been encoded now\n",
    "X.drop(categorical_features, axis=1, inplace=True)\n",
    "X_final_test.drop(categorical_features, axis=1, inplace=True)\n",
    "\n",
    "# Scale the numerical features\n",
    "to_scale = ['invisits', 'length_stay', 'num_meds', 'num_diag', 'num_tests', 'non_lab_procedures', 'sum_visits']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X[to_scale] = scaler.fit_transform(X[to_scale])\n",
    "X_final_test[to_scale] = scaler.transform(X_final_test[to_scale]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "age - Rank: 1\n",
      "invisits - Rank: 1\n",
      "length_stay - Rank: 1\n",
      "num_tests - Rank: 1\n",
      "non_lab_procedures - Rank: 1\n",
      "num_meds - Rank: 1\n",
      "num_diag - Rank: 1\n",
      "change_meds - Rank: 3\n",
      "diabetes_meds - Rank: 39\n",
      "glimepiride - Rank: 37\n",
      "glipizide - Rank: 14\n",
      "glyburide - Rank: 17\n",
      "insulin - Rank: 5\n",
      "pioglitazone - Rank: 27\n",
      "rosiglitazone - Rank: 33\n",
      "metformin - Rank: 11\n",
      "no_meds - Rank: 22\n",
      "sum_visits - Rank: 1\n",
      "diag_3_-1 - Rank: 83\n",
      "diag_3_1 - Rank: 70\n",
      "diag_3_10 - Rank: 32\n",
      "diag_3_11 - Rank: 91\n",
      "diag_3_12 - Rank: 55\n",
      "diag_3_13 - Rank: 68\n",
      "diag_3_14 - Rank: 94\n",
      "diag_3_16 - Rank: 42\n",
      "diag_3_17 - Rank: 67\n",
      "diag_3_18 - Rank: 41\n",
      "diag_3_2 - Rank: 65\n",
      "diag_3_3 - Rank: 6\n",
      "diag_3_4 - Rank: 57\n",
      "diag_3_5 - Rank: 51\n",
      "diag_3_6 - Rank: 69\n",
      "diag_3_7 - Rank: 1\n",
      "diag_3_8 - Rank: 26\n",
      "diag_3_9 - Rank: 49\n",
      "admission_source_0 - Rank: 101\n",
      "admission_source_1 - Rank: 7\n",
      "admission_source_12 - Rank: 15\n",
      "admission_source_13 - Rank: 92\n",
      "admission_source_14 - Rank: 105\n",
      "admission_source_15 - Rank: 46\n",
      "admission_source_3 - Rank: 45\n",
      "admission_source_4 - Rank: 95\n",
      "admission_source_8 - Rank: 82\n",
      "diag_2_-1 - Rank: 96\n",
      "diag_2_1 - Rank: 66\n",
      "diag_2_10 - Rank: 21\n",
      "diag_2_11 - Rank: 93\n",
      "diag_2_12 - Rank: 43\n",
      "diag_2_13 - Rank: 74\n",
      "diag_2_14 - Rank: 98\n",
      "diag_2_16 - Rank: 38\n",
      "diag_2_17 - Rank: 62\n",
      "diag_2_18 - Rank: 59\n",
      "diag_2_2 - Rank: 50\n",
      "diag_2_3 - Rank: 10\n",
      "diag_2_4 - Rank: 53\n",
      "diag_2_5 - Rank: 60\n",
      "diag_2_6 - Rank: 76\n",
      "diag_2_7 - Rank: 2\n",
      "diag_2_8 - Rank: 20\n",
      "diag_2_9 - Rank: 44\n",
      "a1c_test_result_Diabetic - Rank: 30\n",
      "a1c_test_result_Normal - Rank: 47\n",
      "a1c_test_result_Not tested - Rank: 13\n",
      "race_0.0 - Rank: 16\n",
      "race_1.0 - Rank: 86\n",
      "race_2.0 - Rank: 8\n",
      "race_3.0 - Rank: 72\n",
      "race_4.0 - Rank: 75\n",
      "race_Not Registered - Rank: 54\n",
      "disposition_0 - Rank: 100\n",
      "disposition_1 - Rank: 9\n",
      "disposition_11 - Rank: 19\n",
      "disposition_12 - Rank: 97\n",
      "disposition_14 - Rank: 89\n",
      "disposition_20 - Rank: 88\n",
      "disposition_21 - Rank: 28\n",
      "disposition_23 - Rank: 85\n",
      "disposition_4 - Rank: 34\n",
      "disposition_5 - Rank: 87\n",
      "disposition_6 - Rank: 63\n",
      "disposition_7 - Rank: 36\n",
      "disposition_9 - Rank: 71\n",
      "admission_type_0 - Rank: 24\n",
      "admission_type_1 - Rank: 1\n",
      "admission_type_2 - Rank: 104\n",
      "admission_type_3 - Rank: 31\n",
      "admission_type_4 - Rank: 90\n",
      "admission_type_5 - Rank: 103\n",
      "admission_type_6 - Rank: 12\n",
      "glucose_test_result_Diabetic - Rank: 81\n",
      "glucose_test_result_Normal - Rank: 73\n",
      "glucose_test_result_Not tested - Rank: 52\n",
      "glucose_test_result_Probably diabetic - Rank: 79\n",
      "diag_1_-1 - Rank: 102\n",
      "diag_1_1 - Rank: 56\n",
      "diag_1_10 - Rank: 40\n",
      "diag_1_11 - Rank: 84\n",
      "diag_1_12 - Rank: 61\n",
      "diag_1_13 - Rank: 48\n",
      "diag_1_14 - Rank: 99\n",
      "diag_1_16 - Rank: 35\n",
      "diag_1_17 - Rank: 29\n",
      "diag_1_18 - Rank: 77\n",
      "diag_1_2 - Rank: 58\n",
      "diag_1_3 - Rank: 23\n",
      "diag_1_4 - Rank: 80\n",
      "diag_1_5 - Rank: 64\n",
      "diag_1_6 - Rank: 78\n",
      "diag_1_7 - Rank: 4\n",
      "diag_1_8 - Rank: 18\n",
      "diag_1_9 - Rank: 25\n"
     ]
    }
   ],
   "source": [
    "# Undersample the data \n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# Create the RFE with a LogisticRegression estimator and 3 features to select\n",
    "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=10, verbose=1)\n",
    "\n",
    "# Fits the eliminator to the data\n",
    "rfe.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Print the features and their ranking (high = dropped early on)\n",
    "for feature, rank in zip(X.columns, rfe.ranking_):\n",
    "    print(f'{feature} - Rank: {rank}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = pd.DataFrame({'Features': X.columns, 'Ranking' : rfe.ranking_})\n",
    "rankings = rankings.sort_values(by='Ranking')\n",
    "rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mateus\\Documents\\IMS\\ML50-2023\\model_exploration.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mateus/Documents/IMS/ML50-2023/model_exploration.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m X_train_resampled, y_train_resampled \u001b[39m=\u001b[39m rus\u001b[39m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mateus/Documents/IMS/ML50-2023/model_exploration.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Mateus/Documents/IMS/ML50-2023/model_exploration.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m fit,score \u001b[39m=\u001b[39m test_model(model, X_train_resampled, y_train_resampled, X_test, y_test, just_score\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mateus/Documents/IMS/ML50-2023/model_exploration.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Save score\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mateus/Documents/IMS/ML50-2023/model_exploration.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m temp\u001b[39m.\u001b[39mappend(score)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "scores = pd.DataFrame()\n",
    "temp = {}\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = MLPClassifier(hidden_layer_sizes=(4,4,4), activation='logistic', max_iter=500)\n",
    "\n",
    "for num_features in range(20, 50, 2):\n",
    "    temp = []\n",
    "    for i in range(100):\n",
    "        # Select the 5 features with the highest ranking\n",
    "        selected_features = rankings[rankings['Ranking'] < num_features]['Features'].values\n",
    "\n",
    "        # Fit a model using the selected features\n",
    "        X_rfe = X[selected_features]\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "        # Undersample the data\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Fit the model\n",
    "        fit,score = test_model(model, X_train_resampled, y_train_resampled, X_test, y_test, just_score=True)\n",
    "\n",
    "        # Save score\n",
    "        temp.append(score)\n",
    "\n",
    "    temp = pd.DataFrame(temp, columns=[f'{num_features} features'])\n",
    "    scores = pd.concat([scores, temp], axis=1)\n",
    "    print(f'{num_features} features done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New high score: 0.25113545284531125\n",
      "New high score: 0.25314009661835746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New high score: 0.2599192207175101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mateus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New high score: 0.2819466248037677\n",
      "New high score: 0.28290121430915655\n",
      "New high score: 0.28894055131185653\n"
     ]
    }
   ],
   "source": [
    "high_score = 0\n",
    "best_model = None\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(60,60,60,60), activation='relu', max_iter=500)\n",
    "\n",
    "selected_features = rankings[rankings['Ranking'] < 20]['Features'].values\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    # Fit a model using the selected features\n",
    "    X_rfe = X[selected_features]\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_rfe, y, test_size=0.1, shuffle=True)\n",
    "\n",
    "    # Undersample the data\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Fit the model\n",
    "    fit,score = test_model(model, X_train_resampled, y_train_resampled, X_test, y_test, just_score=True)\n",
    "\n",
    "    if score > high_score:\n",
    "        high_score = score\n",
    "        best_model = fit\n",
    "        print(f'New high score: {high_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use the fit to predict the \n",
    "y_pred = best_model.predict(X_final_test[selected_features])\n",
    "\n",
    "# Lets save the predictions\n",
    "predictions = pd.DataFrame(y_pred, index=X_final_test.index, columns=['readmitted_binary'])\n",
    "predictions['readmitted_binary'].apply(lambda x: 'Yes' if x == 1 else 'No').to_csv('predictions.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
